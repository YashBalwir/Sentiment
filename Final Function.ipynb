{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_S(test_file_path):\n",
    "    \n",
    "    #path to the pickled model file and vector\n",
    "    model_path = \"./Data/model.pickle\"\n",
    "    tfidf_vectorizer_path = \"./Data/tfidf_vectorizer.pickle\"\n",
    "    \n",
    "    try:\n",
    "        f = open(model_path, \"rb\")\n",
    "        model = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        f = open(tfidf_vectorizer_path, \"rb\")\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        df_test = pd.read_csv(test_file_path)\n",
    "        \n",
    "        reviews = df_test.review\n",
    "        X = tfidf_vectorizer.transform(reviews)\n",
    "        \n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        prob = model.predict_proba(X)\n",
    "        \n",
    "        scores = [x[0][0] if x[1] == 'neg' else x[0][1] for x in zip(prob,y_pred)]\n",
    "        \n",
    "        ids = df_test.id\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for senti,score,id_ in zip(y_pred,scores,ids):\n",
    "            if str(score*10)[0] == \"5\":\n",
    "                senti = 'neutral'\n",
    "            results.append({\"sentiment\":senti,\"score\":score,\"customer_id\":id_})\n",
    "        \n",
    "        arr = []\n",
    "        for product,senti in df_test.product,y_pred:\n",
    "            positive = 0\n",
    "            negative = 0\n",
    "            if product\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return {\"Error\": \"Model not found or csv file encoding is different\"}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentiment': 'neg', 'score': 0.8738437602296608, 'customer_id': 9900}, {'sentiment': 'pos', 'score': 0.6813979665602383, 'customer_id': 9901}, {'sentiment': 'neg', 'score': 0.6806646124904225, 'customer_id': 9902}, {'sentiment': 'neutral', 'score': 0.5347183475458966, 'customer_id': 9903}, {'sentiment': 'neg', 'score': 0.7147136165934684, 'customer_id': 9904}, {'sentiment': 'neg', 'score': 0.7732930170799471, 'customer_id': 9905}, {'sentiment': 'neg', 'score': 0.8146206885457417, 'customer_id': 9906}, {'sentiment': 'neg', 'score': 0.9667768426946755, 'customer_id': 9907}, {'sentiment': 'neutral', 'score': 0.5853048131437749, 'customer_id': 9908}, {'sentiment': 'pos', 'score': 0.6290963154556456, 'customer_id': 9909}, {'sentiment': 'pos', 'score': 0.7607622082595913, 'customer_id': 9910}, {'sentiment': 'pos', 'score': 0.9819189188994002, 'customer_id': 9911}, {'sentiment': 'neg', 'score': 0.6181355716652074, 'customer_id': 9912}, {'sentiment': 'neutral', 'score': 0.5988492195958979, 'customer_id': 9913}, {'sentiment': 'neg', 'score': 0.821887714325616, 'customer_id': 9914}, {'sentiment': 'neutral', 'score': 0.51820276088628, 'customer_id': 9915}, {'sentiment': 'pos', 'score': 0.9695275972201031, 'customer_id': 9916}, {'sentiment': 'pos', 'score': 0.6076992872129612, 'customer_id': 9917}, {'sentiment': 'neg', 'score': 0.7686892018907883, 'customer_id': 9918}, {'sentiment': 'pos', 'score': 0.8418162658021568, 'customer_id': 9919}, {'sentiment': 'neg', 'score': 0.8069973249308864, 'customer_id': 9920}, {'sentiment': 'pos', 'score': 0.8485353837869201, 'customer_id': 9921}, {'sentiment': 'neg', 'score': 0.6732897562938396, 'customer_id': 9922}, {'sentiment': 'pos', 'score': 0.7997727582804471, 'customer_id': 9923}, {'sentiment': 'pos', 'score': 0.7620872192980627, 'customer_id': 9924}, {'sentiment': 'neg', 'score': 0.737803613632747, 'customer_id': 9925}, {'sentiment': 'neg', 'score': 0.9316612626425939, 'customer_id': 9926}, {'sentiment': 'neg', 'score': 0.6562320447419698, 'customer_id': 9927}, {'sentiment': 'neg', 'score': 0.8665576843438623, 'customer_id': 9928}, {'sentiment': 'neg', 'score': 0.8726705103704071, 'customer_id': 9929}, {'sentiment': 'neg', 'score': 0.8389911796855187, 'customer_id': 9930}, {'sentiment': 'neg', 'score': 0.9710228566880903, 'customer_id': 9931}, {'sentiment': 'neg', 'score': 0.7042500285164561, 'customer_id': 9932}, {'sentiment': 'neg', 'score': 0.9391809226372672, 'customer_id': 9933}, {'sentiment': 'neg', 'score': 0.6781747151034984, 'customer_id': 9934}, {'sentiment': 'neg', 'score': 0.7893477162156506, 'customer_id': 9935}, {'sentiment': 'pos', 'score': 0.6445284400429693, 'customer_id': 9936}, {'sentiment': 'neg', 'score': 0.7320411074588229, 'customer_id': 9937}, {'sentiment': 'neutral', 'score': 0.5875104796235868, 'customer_id': 9938}, {'sentiment': 'pos', 'score': 0.7904907929612622, 'customer_id': 9939}, {'sentiment': 'neutral', 'score': 0.5537370952848284, 'customer_id': 9940}, {'sentiment': 'neutral', 'score': 0.528817681811969, 'customer_id': 9941}, {'sentiment': 'neg', 'score': 0.725869299651632, 'customer_id': 9942}, {'sentiment': 'pos', 'score': 0.7215183437926913, 'customer_id': 9943}, {'sentiment': 'neutral', 'score': 0.5179371489253501, 'customer_id': 9944}, {'sentiment': 'pos', 'score': 0.8820913587060638, 'customer_id': 9945}, {'sentiment': 'pos', 'score': 0.7408376954378115, 'customer_id': 9946}, {'sentiment': 'pos', 'score': 0.9023048350432026, 'customer_id': 9947}, {'sentiment': 'pos', 'score': 0.6607587955648068, 'customer_id': 9948}, {'sentiment': 'neg', 'score': 0.6595213358228182, 'customer_id': 9949}, {'sentiment': 'neg', 'score': 0.804194465164837, 'customer_id': 9950}, {'sentiment': 'neg', 'score': 0.7805093004280127, 'customer_id': 9951}, {'sentiment': 'neg', 'score': 0.8148439394674848, 'customer_id': 9952}, {'sentiment': 'neg', 'score': 0.6829361040079464, 'customer_id': 9953}, {'sentiment': 'neutral', 'score': 0.5941519152758626, 'customer_id': 9954}, {'sentiment': 'neg', 'score': 0.9877168044437925, 'customer_id': 9955}, {'sentiment': 'neg', 'score': 0.9651492595030229, 'customer_id': 9956}, {'sentiment': 'neg', 'score': 0.6922021647805348, 'customer_id': 9957}, {'sentiment': 'pos', 'score': 0.6280309956597566, 'customer_id': 9958}, {'sentiment': 'pos', 'score': 0.6034980222658382, 'customer_id': 9959}, {'sentiment': 'pos', 'score': 0.6022143380915347, 'customer_id': 9960}, {'sentiment': 'pos', 'score': 0.7075324590373344, 'customer_id': 9961}, {'sentiment': 'pos', 'score': 0.6224470204725996, 'customer_id': 9962}, {'sentiment': 'neutral', 'score': 0.5325966256058705, 'customer_id': 9963}, {'sentiment': 'neg', 'score': 0.732247414391735, 'customer_id': 9964}, {'sentiment': 'neg', 'score': 0.7672238692350366, 'customer_id': 9965}, {'sentiment': 'pos', 'score': 0.6902768716808843, 'customer_id': 9966}, {'sentiment': 'neutral', 'score': 0.5821751059281562, 'customer_id': 9967}, {'sentiment': 'pos', 'score': 0.8841249691127672, 'customer_id': 9968}, {'sentiment': 'neg', 'score': 0.6752761996273036, 'customer_id': 9969}, {'sentiment': 'neg', 'score': 0.7602248923569053, 'customer_id': 9970}, {'sentiment': 'neutral', 'score': 0.5600407581833013, 'customer_id': 9971}, {'sentiment': 'neutral', 'score': 0.5934471123767919, 'customer_id': 9972}, {'sentiment': 'neutral', 'score': 0.5937658327177426, 'customer_id': 9973}, {'sentiment': 'neutral', 'score': 0.5329392550105037, 'customer_id': 9974}, {'sentiment': 'neg', 'score': 0.6032184999176082, 'customer_id': 9975}, {'sentiment': 'neutral', 'score': 0.5173104811195847, 'customer_id': 9976}, {'sentiment': 'pos', 'score': 0.6088042499311411, 'customer_id': 9977}, {'sentiment': 'neutral', 'score': 0.5819846236113047, 'customer_id': 9978}, {'sentiment': 'pos', 'score': 0.9132990160471175, 'customer_id': 9979}, {'sentiment': 'neutral', 'score': 0.594380345382781, 'customer_id': 9980}, {'sentiment': 'pos', 'score': 0.8311896590002612, 'customer_id': 9981}, {'sentiment': 'pos', 'score': 0.6629645540199098, 'customer_id': 9982}, {'sentiment': 'pos', 'score': 0.7779487845993657, 'customer_id': 9983}, {'sentiment': 'neg', 'score': 0.7613188398496985, 'customer_id': 9984}, {'sentiment': 'pos', 'score': 0.7689885197593154, 'customer_id': 9985}, {'sentiment': 'pos', 'score': 0.6140884948837728, 'customer_id': 9986}, {'sentiment': 'pos', 'score': 0.7286802744939023, 'customer_id': 9987}, {'sentiment': 'neutral', 'score': 0.5997162437151065, 'customer_id': 9988}, {'sentiment': 'neutral', 'score': 0.5698008891940289, 'customer_id': 9989}, {'sentiment': 'pos', 'score': 0.7858451343947463, 'customer_id': 9990}, {'sentiment': 'pos', 'score': 0.6728400314629878, 'customer_id': 9991}, {'sentiment': 'pos', 'score': 0.6343611914739923, 'customer_id': 9992}, {'sentiment': 'neutral', 'score': 0.5687637740870701, 'customer_id': 9993}, {'sentiment': 'pos', 'score': 0.7029006898740265, 'customer_id': 9994}, {'sentiment': 'pos', 'score': 0.7767819140428898, 'customer_id': 9995}, {'sentiment': 'pos', 'score': 0.6709353756839758, 'customer_id': 9996}, {'sentiment': 'neg', 'score': 0.7837218212535999, 'customer_id': 9997}, {'sentiment': 'neg', 'score': 0.9672562234359335, 'customer_id': 9998}, {'sentiment': 'pos', 'score': 0.7774969459454429, 'customer_id': 9999}]\n"
     ]
    }
   ],
   "source": [
    "print(Sentiment_S(\"reviews_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_txt(textfile_path):\n",
    "    #path to the pickled model file and vector\n",
    "    model_path = \"./Data/model.pickle\"\n",
    "    tfidf_vectorizer_path = \"./Data/tfidf_vectorizer.pickle\"\n",
    "    \n",
    "    try:\n",
    "        #txt preprocessing\n",
    "        reviews = []\n",
    "        ids = []\n",
    "        \n",
    "        with open(textfile_path,\"r\") as f:\n",
    "            sentences = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        sentences = sentences.strip()\n",
    "        sentences = sentences.split(\"\\n\")\n",
    "        \n",
    "        for sent in sentences:\n",
    "            ids.append(sent[:4])\n",
    "            reviews.append(sent[5:])\n",
    "            \n",
    "        f = open(model_path,\"rb\")\n",
    "        model = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        f = open(tfidf_vectorizer_path,\"rb\")\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        tfidf_matrix = tfidf_vectorizer.transform(reviews)\n",
    "        \n",
    "        y_pred = model.predict(tfidf_matrix)\n",
    "        \n",
    "        prob = model.predict_proba(tfidf_matrix)\n",
    "        \n",
    "        scores = [x[0][0] if x[1] == 'neg' else x[0][1] for x in zip(prob,y_pred)]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for senti,score,id_ in zip(y_pred,scores,ids):\n",
    "            if str(score*10)[0] == \"5\":\n",
    "                senti = \"neutral\"\n",
    "            results.append({\"sentiment\":senti,\"score\":score,\"customer_id\":id_})\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return {\"Error\": \"Model not found or txt file encoding is different\"}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentiment': 'neutral', 'score': 0.594380345382781, 'customer_id': '9980'}, {'sentiment': 'pos', 'score': 0.8311896590002612, 'customer_id': '9981'}, {'sentiment': 'pos', 'score': 0.6629645540199098, 'customer_id': '9982'}, {'sentiment': 'pos', 'score': 0.7779487845993657, 'customer_id': '9983'}, {'sentiment': 'neg', 'score': 0.7613188398496985, 'customer_id': '9984'}, {'sentiment': 'pos', 'score': 0.7689885197593154, 'customer_id': '9985'}, {'sentiment': 'pos', 'score': 0.6140884948837728, 'customer_id': '9986'}, {'sentiment': 'pos', 'score': 0.7286802744939023, 'customer_id': '9987'}, {'sentiment': 'neutral', 'score': 0.5997162437151065, 'customer_id': '9988'}, {'sentiment': 'neutral', 'score': 0.5698008891940289, 'customer_id': '9989'}]\n"
     ]
    }
   ],
   "source": [
    "print(Sentiment_txt(\"./reviews.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_S(test_file_path):\n",
    "    \n",
    "    #path to the pickled model file and vector\n",
    "    model_path = \"./Data/model.pickle\"\n",
    "    tfidf_vectorizer_path = \"./Data/tfidf_vectorizer.pickle\"\n",
    "    \n",
    "    try:\n",
    "        f = open(model_path, \"rb\")\n",
    "        model = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        f = open(tfidf_vectorizer_path, \"rb\")\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        df_test = pd.read_csv(test_file_path)\n",
    "        \n",
    "        reviews = df_test.review\n",
    "        X = tfidf_vectorizer.transform(reviews)\n",
    "        \n",
    "        #y_pred = model.predict(X)\n",
    "        df_test['predictions'] = model.predict(X)\n",
    "        \n",
    "        arr = []\n",
    "        for prod in df_test['product'].unique():\n",
    "            pos = df_test[df_test['product'] == prod]['predictions'].value_counts()['pos']\n",
    "            neg = df_test[df_test['product'] == prod]['predictions'].value_counts()['neg']\n",
    "            arr.append({'product':prod,'positive':pos,\"negative\":neg})\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        tot_pos = df_test[df_test['predictions'] == 'pos'].count()[0]\n",
    "        tot_neg = df_test[df_test['predictions'] == 'neg'].count()[0]\n",
    "        \n",
    "        results.append(arr)\n",
    "        results.append({\"total_positive\":tot_pos,\"total_negative\":tot_neg})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return {\"Error\": \"Model not found or csv file encoding is different\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'product': 'product 1', 'positive': 10, 'negative': 10}, {'product': 'product 5', 'positive': 10, 'negative': 10}, {'product': 'product 2', 'positive': 8, 'negative': 12}, {'product': 'product 4', 'positive': 13, 'negative': 7}, {'product': 'product 3', 'positive': 11, 'negative': 9}], {'total_positive': 52, 'total_negative': 48}]\n"
     ]
    }
   ],
   "source": [
    "print(Sentiment_S(\"prod_reviews.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"prod_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>review</th>\n",
       "      <th>id</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9900</td>\n",
       "      <td>horror for ten year olds: Half a dozen women g...</td>\n",
       "      <td>9900</td>\n",
       "      <td>product 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9901</td>\n",
       "      <td>LOUSY: This movie was about an inch of me gong...</td>\n",
       "      <td>9901</td>\n",
       "      <td>product 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9902</td>\n",
       "      <td>Dumb and Dumber and Dumber and: Six macho bise...</td>\n",
       "      <td>9902</td>\n",
       "      <td>product 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9903</td>\n",
       "      <td>FAIR: THE MOVIE FOR ME STARTED WHEN THEY GOT L...</td>\n",
       "      <td>9903</td>\n",
       "      <td>product 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9904</td>\n",
       "      <td>descent into stupidity: I just watched this fo...</td>\n",
       "      <td>9904</td>\n",
       "      <td>product 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0           0             0            9900   \n",
       "1           1             1            9901   \n",
       "2           2             2            9902   \n",
       "3           3             3            9903   \n",
       "4           4             4            9904   \n",
       "\n",
       "                                              review    id    product  \n",
       "0  horror for ten year olds: Half a dozen women g...  9900  product 1  \n",
       "1  LOUSY: This movie was about an inch of me gong...  9901  product 5  \n",
       "2  Dumb and Dumber and Dumber and: Six macho bise...  9902  product 2  \n",
       "3  FAIR: THE MOVIE FOR ME STARTED WHEN THEY GOT L...  9903  product 2  \n",
       "4  descent into stupidity: I just watched this fo...  9904  product 5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
